[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://python.org)
[![MySQL](https://img.shields.io/badge/MySQL-8.0-orange.svg)](https://www.mysql.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.50-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

# Sistema ETL: Sakila OLTP â†’ Data Mart OLAP + Dashboard Interactivo

Proyecto acadÃ©mico de ETL que transforma datos de una base de datos transaccional (Sakila) a un modelo dimensional optimizado para anÃ¡lisis de negocio, con dashboard interactivo en Streamlit.

## DescripciÃ³n del Proyecto

Este proyecto implementa un proceso ETL completo que extrae datos del sistema operacional Sakila (simulando una tienda de alquiler de pelÃ­culas), realiza validaciones de calidad, limpieza y transformaciones, para finalmente cargar los datos en un Data Mart con esquema estrella optimizado para consultas analÃ­ticas.

**Nuevo:** Incluye dashboard interactivo desarrollado con Streamlit para visualizaciÃ³n de datos en tiempo real.

### Objetivo

Demostrar la diferencia de rendimiento entre consultas OLTP (Online Transaction Processing) sobre bases de datos normalizadas versus consultas OLAP (Online Analytical Processing) sobre modelos dimensionales desnormalizados, con capacidad de anÃ¡lisis visual mediante dashboard web.

## Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sakila (OLTP)  â”‚  â† Base de datos transaccional (normalizada 3FN)
â”‚   MySQL Local   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ExtracciÃ³n (Python + SQLAlchemy)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Staging Area    â”‚  â† Ãrea intermedia para limpieza y validaciÃ³n
â”‚ sakila_staging  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ TransformaciÃ³n (Pandas + SQL)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Mart      â”‚  â† Modelo Estrella (OLAP)
â”‚  sakila_dw      â”‚  â†’ 4 Dimensiones + 1 Tabla de Hechos
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚  â”‚   Power BI      â”‚
â”‚   Dashboard     â”‚  â”‚   (Opcional)    â”‚
â”‚  (Interactivo)  â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## TecnologÃ­as Utilizadas

- **Python 3.12** - Lenguaje principal
- **UV** - Gestor de paquetes y entornos virtuales
- **MySQL 8.0** - Base de datos
- **Jupyter Notebook** - Desarrollo interactivo
- **Pandas** - ManipulaciÃ³n de datos
- **SQLAlchemy** - ORM y conexiones
- **Streamlit** - Dashboard web interactivo
- **Plotly** - Visualizaciones interactivas
- **Power BI** - VisualizaciÃ³n (opcional)

### LibrerÃ­as Python

```
pandas
numpy
sqlalchemy
pymysql
cryptography
python-dotenv
colorlog
jupyter
ipykernel
streamlit
plotly
altair
```

## Requisitos Previos

1. Python 3.11+
2. MySQL 8.0+ instalado y corriendo
3. Base de datos Sakila cargada
4. UV instalado (`curl -LsSf https://astral.sh/uv/install.sh | sh`)

## InstalaciÃ³n

### 1. Clonar/Descargar el proyecto

```bash
cd ruta/del/proyecto
```

### 2. Instalar dependencias con UV

```bash
# Dependencias principales
uv add pandas numpy sqlalchemy pymysql cryptography python-dotenv colorlog jupyter ipykernel

# Dependencias para dashboard
uv add streamlit plotly
```

### 3. Configurar credenciales

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# Base de datos Sakila (origen)
SAKILA_HOST=localhost
SAKILA_PORT=3306
SAKILA_USER=root
SAKILA_PASSWORD=tu_password
SAKILA_DATABASE=sakila

# Data Mart (destino)
DM_HOST=localhost
DM_PORT=3306
DM_USER=root
DM_PASSWORD=tu_password
DM_DATABASE=sakila_dw

# Staging
STAGING_DATABASE=sakila_staging

# ETL Config
ETL_BATCH_SIZE=1000
ETL_LOG_LEVEL=INFO
ETL_LOG_PATH=logs/
```

### 4. Verificar configuraciÃ³n

```bash
uv run jupyter notebook
# Abrir: notebooks/00_test_config.ipynb
# Ejecutar todas las celdas
```

## Estructura del Proyecto

```
appBigData/
â”œâ”€â”€ .env                          # Credenciales (NO subir a Git)
â”œâ”€â”€ .env.example                 # Plantilla de credenciales
â”œâ”€â”€ .gitignore                   # Archivos excluidos
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ STREAMLIT_DASHBOARD.md       # DocumentaciÃ³n del dashboard
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                # ConfiguraciÃ³n centralizada
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ etl_YYYYMMDD.log        # Logs por fecha
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_test_config.ipynb    # VerificaciÃ³n inicial
â”‚   â”œâ”€â”€ 01_extraccion.ipynb     # ExtracciÃ³n de Sakila
â”‚   â”œâ”€â”€ 02_staging.ipynb        # Validaciones y limpieza
â”‚   â””â”€â”€ 03_transformacion.ipynb # Modelo estrella
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_staging.sql      # Schema de staging
â”‚   â””â”€â”€ create_datamart.sql     # Schema Data Mart
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger_config.py        # Sistema de logging
â”‚   â”œâ”€â”€ extractor.py            # MÃ³dulo de extracciÃ³n
â”‚   â”œâ”€â”€ validator.py            # Validaciones de calidad
â”‚   â”œâ”€â”€ staging.py              # Procesamiento staging
â”‚   â””â”€â”€ transformer.py          # Transformaciones DM
â””â”€â”€ streamlit_app/               # Dashboard interactivo
    â”œâ”€â”€ app.py                   # PÃ¡gina principal
    â”œâ”€â”€ pages/                   # PÃ¡ginas del dashboard
    â”‚   â”œâ”€â”€ 1_ğŸ“Š_Ventas.py
    â”‚   â”œâ”€â”€ 2_ğŸ¬_PelÃ­culas.py
    â”‚   â”œâ”€â”€ 3_ğŸ“‚_CategorÃ­as.py
    â”‚   â””â”€â”€ 4_ğŸª_Tiendas.py
    â”œâ”€â”€ components/              # Componentes reutilizables
    â”‚   â”œâ”€â”€ kpi_cards.py
    â”‚   â”œâ”€â”€ filters.py
    â”‚   â””â”€â”€ charts.py
    â””â”€â”€ utils/                   # Utilidades
        â”œâ”€â”€ db_connection.py
        â””â”€â”€ queries.py
```

## Uso del Sistema

### OpciÃ³n 1: ETL Paso a Paso (Notebooks)

```bash
# Iniciar Jupyter
uv run jupyter notebook

# Ejecutar notebooks en orden:
# 1. notebooks/01_extraccion.ipynb
# 2. notebooks/02_staging.ipynb
# 3. notebooks/03_transformacion.ipynb
```

### OpciÃ³n 2: ETL Automatizado (Script)

```bash
# ExtracciÃ³n completa (primera vez)
uv run python main_etl.py

# ExtracciÃ³n incremental (cargas posteriores)
uv run python main_etl.py --incremental

# Sin confirmaciÃ³n (para automatizaciÃ³n)
uv run python main_etl.py --force
```

### OpciÃ³n 3: Dashboard Interactivo (Streamlit)

```bash
# Ejecutar dashboard
uv run streamlit run streamlit_app/app.py

# El dashboard se abrirÃ¡ en: http://localhost:8501
```

## Dashboard Interactivo Streamlit

### CaracterÃ­sticas del Dashboard

- **PÃ¡gina Principal**: KPIs generales, resumen ejecutivo y visualizaciones clave
- **AnÃ¡lisis de Ventas**: Tendencias temporales, comparativas por tienda y categorÃ­a
- **AnÃ¡lisis de PelÃ­culas**: Top rankings, clasificaciones, correlaciones
- **AnÃ¡lisis de CategorÃ­as**: Performance por gÃ©nero, evoluciÃ³n temporal
- **AnÃ¡lisis de Tiendas**: Comparativas, grÃ¡ficos radar, evoluciÃ³n individual

### Funcionalidades

- Filtros dinÃ¡micos por fecha, categorÃ­a y tienda
- ExportaciÃ³n de datos a CSV
- Visualizaciones interactivas con Plotly
- Cache inteligente para mejor performance
- Responsive design para diferentes dispositivos

### Capturas de Pantalla

(Ver documentaciÃ³n completa en [STREAMLIT_DASHBOARD.md](STREAMLIT_DASHBOARD.md))

## Modelo de Datos

### Modelo Estrella (Star Schema)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  dim_tiempo  â”‚
                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                    â”‚ fecha_id PK  â”‚
                    â”‚ fecha        â”‚
                    â”‚ aÃ±o          â”‚
                    â”‚ mes          â”‚
                    â”‚ trimestre    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  dim_film    â”‚       â”‚       â”‚ dim_categoriaâ”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚       â”‚       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚ film_sk PK   â”‚       â”‚       â”‚categoria_sk  â”‚
    â”‚ film_id      â”‚       â”‚       â”‚categoria_id  â”‚
    â”‚ titulo       â”‚       â”‚       â”‚nombre        â”‚
    â”‚ tarifa_renta â”‚       â”‚       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚              â”‚
           â”‚               â”‚              â”‚
           â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
           â””â”€â”€â”€â”€â”€â”€â”¤  fact_ventas    â”œâ”€â”€â”€â”€â”€â”˜
                  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                  â”‚ venta_id PK     â”‚
                  â”‚ fecha_id FK     â”‚
                  â”‚ film_sk FK      â”‚
                  â”‚ categoria_sk FK â”‚
                  â”‚ tienda_sk FK    â”‚
                  â”‚ cantidad_rentas â”‚
                  â”‚ monto_total     â”‚
                  â”‚ monto_promedio  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  dim_tienda    â”‚
                  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                  â”‚ tienda_sk PK   â”‚
                  â”‚ tienda_id      â”‚
                  â”‚ nombre         â”‚
                  â”‚ ciudad         â”‚
                  â”‚ pais           â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dimensiones

**dim_tiempo**
- 8,035 registros (2005-2026)
- Atributos: aÃ±o, mes, trimestre, dÃ­a_semana
- Granularidad: dÃ­a

**dim_film**
- 1,000 pelÃ­culas
- SCD Type 2: Rastrea cambios en tarifas
- Atributos: tÃ­tulo, duraciÃ³n, rating, costo

**dim_categoria**
- 16 categorÃ­as
- Atributos: nombre, descripciÃ³n

**dim_tienda**
- 2 tiendas
- Atributos: ubicaciÃ³n completa (ciudad, paÃ­s)

### Tabla de Hechos

**fact_ventas**
- Granularidad: fecha + film + categorÃ­a + tienda
- MÃ©tricas:
  - cantidad_rentas
  - monto_total
  - monto_promedio
  - dias_renta_promedio
  - cantidad_devoluciones

## Vistas AnalÃ­ticas Predefinidas

El sistema incluye 4 vistas optimizadas para anÃ¡lisis de negocio:

### 1. v_top_films_categoria
Top pelÃ­culas mÃ¡s rentadas por categorÃ­a
```sql
SELECT * FROM v_top_films_categoria;
```

### 2. v_ventas_mensuales_tienda
EvoluciÃ³n mensual de ventas por tienda
```sql
SELECT * FROM v_ventas_mensuales_tienda 
WHERE anio = 2005;
```

### 3. v_performance_categoria
Performance consolidado por categorÃ­a
```sql
SELECT * FROM v_performance_categoria 
ORDER BY ingresos_totales DESC;
```

### 4. v_resumen_ejecutivo
KPIs ejecutivos mensuales
```sql
SELECT * FROM v_resumen_ejecutivo 
ORDER BY anio DESC, mes DESC 
LIMIT 12;
```

## MÃ©tricas de Calidad

El sistema implementa validaciones automÃ¡ticas:

- ValidaciÃ³n de duplicados en PKs
- ValidaciÃ³n de valores nulos en campos requeridos
- ValidaciÃ³n de rangos numÃ©ricos (montos â‰¥ 0)
- Integridad referencial (foreign keys vÃ¡lidas)
- Consistencia de totales entre tablas

Resultados registrados en: `sakila_staging.audit_calidad`

## Logs y AuditorÃ­a

### Sistema de Logging

- Logs en consola con colores
- Logs en archivo: `logs/etl_YYYYMMDD.log`
- Niveles: INFO, WARNING, ERROR

### Tabla de Control ETL

```sql
SELECT * FROM sakila_staging.etl_control 
ORDER BY etl_id DESC;
```

Registra:
- Proceso ejecutado
- Fecha/hora inicio y fin
- Registros leÃ­dos/escritos/error
- DuraciÃ³n en segundos
- Estado (INICIADO/COMPLETADO/ERROR)

## ComparaciÃ³n de Performance

### Benchmark: OLTP vs OLAP

Query: "Top 20 pelÃ­culas por ingresos con categorÃ­a"

**OLTP (Sakila normalizado)**
- 6 JOINs necesarios
- Tiempo promedio: ~0.15 segundos

**OLAP (Data Mart estrella)**
- 3 JOINs (dimensiones pre-agregadas)
- Tiempo promedio: ~0.05 segundos

**Mejora: 3x mÃ¡s rÃ¡pido**

## CaracterÃ­sticas Avanzadas

### SCD Type 2 (Slowly Changing Dimensions)

Implementado en `dim_film` para rastrear cambios histÃ³ricos:

- Registra versiones anteriores de pelÃ­culas
- Mantiene historial de tarifas
- Campos de control: `fecha_inicio`, `fecha_fin`, `activo`, `version`

Ejemplo:
```sql
-- Ver historial de una pelÃ­cula
SELECT * FROM dim_film 
WHERE film_id = 1 
ORDER BY version;
```

### ExtracciÃ³n Incremental

El sistema soporta cargas incrementales:

```python
from src.extractor import SakilaExtractor

extractor = SakilaExtractor()
# Extrae solo registros nuevos desde Ãºltima carga
stats = extractor.extraer_todas_las_tablas(incremental=True)
```

## Troubleshooting

### Error: Access denied for user 'root'@'localhost'

Verificar credenciales en `.env` y permisos de usuario MySQL:
```sql
GRANT ALL PRIVILEGES ON sakila.* TO 'root'@'localhost';
GRANT ALL PRIVILEGES ON sakila_staging.* TO 'root'@'localhost';
GRANT ALL PRIVILEGES ON sakila_dw.* TO 'root'@'localhost';
FLUSH PRIVILEGES;
```

### Error: cryptography package is required

```bash
uv add cryptography
```

### Error: Column 'es_valido' doesn't exist

Ejecutar celda de preparaciÃ³n en notebook 02 que agrega columnas de validaciÃ³n.

### Problema: Foreign key constraint en DROP TABLE

Las dimensiones deben limpiarse con `TRUNCATE` en lugar de `DROP`:
```sql
SET FOREIGN_KEY_CHECKS = 0;
TRUNCATE TABLE dim_tiempo;
SET FOREIGN_KEY_CHECKS = 1;
```

### Dashboard no carga datos

Verificar:
1. ETL ejecutado correctamente
2. Base de datos sakila_dw poblada
3. Credenciales en .env correctas
4. ConexiÃ³n MySQL activa

## Limitaciones Conocidas

1. Campo `location` (GEOMETRY) de tabla `address` excluido por incompatibilidad
2. Sistema optimizado para cargas batch, no streaming
3. SCD Type 2 solo implementado en `dim_film` como ejemplo

## Mejoras Futuras

- Implementar Apache Airflow para orquestaciÃ³n
- Agregar soporte para mÃºltiples fuentes (web, APIs)
- Implementar particionamiento de fact_ventas por fecha
- Agregar Ã­ndices columnares para queries mÃ¡s complejas
- Predicciones con Machine Learning
- Tests unitarios para mÃ³dulos ETL
- AutenticaciÃ³n en dashboard
- Deployment en cloud

## Requisitos Funcionales Implementados

- RF1: ExtracciÃ³n de datos de Sakila âœ…
- RF2: Staging / Ã¡rea intermedia âœ…
- RF3-4: Transformaciones analÃ­ticas / Data Mart âœ…
- RF5: Consultas analÃ­ticas / reporting âœ…
- RF6: VisualizaciÃ³n interactiva (Streamlit) âœ…
- RF7: AuditorÃ­a / logging âœ…
- RF8: Validaciones de calidad de datos âœ…
- RF9: Manejo de errores âœ…
- RF10: OrquestaciÃ³n del proceso âœ…

## Requisitos No Funcionales Cumplidos

- Performance: ETL completo < 2 minutos âœ…
- Escalabilidad: Arquitectura modular extensible âœ…
- Confiabilidad: Manejo de errores y reintentos âœ…
- Seguridad: Credenciales en .env, no en cÃ³digo âœ…
- Mantenibilidad: CÃ³digo modular y documentado âœ…
- Usabilidad: Dashboard intuitivo y responsive âœ…
- DocumentaciÃ³n: README, docstrings, comentarios âœ…

## DocumentaciÃ³n Adicional

- **[STREAMLIT_DASHBOARD.md](STREAMLIT_DASHBOARD.md)** - GuÃ­a completa del dashboard
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Arquitectura tÃ©cnica del sistema
- **[DATA_DICTIONARY.md](DATA_DICTIONARY.md)** - Diccionario de datos completo

## Autor

Leodan Merino Daza  
Proyecto acadÃ©mico - SENATI Octavo Ciclo  
Curso: Big Data y AnÃ¡lisis de Datos

## Licencia

Proyecto educativo - Uso acadÃ©mico
<e>